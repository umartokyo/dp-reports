Not long ago, LLM's such as ChatGPT have emerged, demonstrating the capabilities of Artificial Intelligence (AI) across a wide range of language-based tasks (11). However, as major AI labs have been increasing the training data and size of these models, the performance gains appear to be plateauing (10). One of the core reasons is thought to be the reliance of these models on human-generated data: they learn to generalise from patterns of our behaviour, thus they are limited to human performance (12). Gladly, this pattern of stagnation is not new; a similar bottleneck was once met in another domain: computer chess. (13)

Traditional chess engines based on the rule-based search algorithms such as heuristic evaluation functions with alpha-beta pruning proved successful in defeating the world champion of the time Gary Kasparov and kept improving ever since (14). Although the strength of these engines exceeded human performance by a large margin, progress was limited by the expertise of human experts who've expressed their strategies through careful manual tuning of parameters (4). Additionally, attempts to introduce a deep learning approach failed as engines built with this paradigm, while successful, struggled to match higher-end classical chess engines, with speculations that this is due to the fact they were trained on human gameplay data. (15)

In 2016, DeepMind introduced AlphaGo - an AI agent which learned to play the game of Go not by mimicking human play, but training entirely through self-play. (16) Go is considered to be a complex game with significantly more possible moves on every turn than atoms in the universe! A major breakthrough of this approach was that AlphaGo has beaten the world champion Lee Sedol in the game which was long believed to require intuition and impossible to brute-force. (16)

Next, DeepMind developed AlphaZero, a general-purpose reinforcement learning agent capable of mastering any two player, perfect information game. (7) Relying on deep neural networks and Monte Carlo Tree Search, when applied to chess, AlphaZero decisively defeated stockfish - the strongest chess engine at the time - in a closed 100 game match, winning 28 games and drawing 72 without a single loss. (8)

This development marked a fundamental shift in the way AI systems can learn. Instead of relying on a large collection of human data, self-play agents are capable of surpassing human knowledge entirely, discovering strategies that were previously unimaginable and are incomprehensible by humans. (8) Potentially, if mathematics of AlphaZero can be generalised beyond games to domains such as reasoning or language, they may be the element which improves the AI models to superhuman levels potentially achieving super-intelligence in the near future.

This paper explores the extent to which self-trained reinforcement learning agents like AlphaZero can outperform traditional heuristic search-based systems such as Stockfish. Through an analysis of their underlying algorithms and empirical match outcomes, the paper seeks to understand the strengths and limitations of each approach.